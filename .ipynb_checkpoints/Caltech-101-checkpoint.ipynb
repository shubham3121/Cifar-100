{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caltech-101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we train a CNN to classify images from the Caltech-101 database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "np.random.seed(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    img_files = np.array(data['filenames'])\n",
    "    img_target = np_utils.to_categorical(np.array(data['target']), num_classes=101)\n",
    "    return img_files, img_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, train_target = load_dataset('101_ObjectCategories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = [item[21:] for item in sorted(glob('101_ObjectCategories/*'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 101 total different categories.\n",
      "There are 8677 total images in the dataset.\n"
     ]
    }
   ],
   "source": [
    "print('There are %d total different categories.'%len(img_names))\n",
    "print('There are %s total images in the dataset.'%len(train_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    #loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # Returns 4D tensor with shape (1, 224, 224, 3)\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "#### pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8677, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_tensors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Obtain Bottleneck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "86409216/87910968 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "def bottleneck_features(tensor):\n",
    "    #from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "    from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "    model = InceptionV3(weights='imagenet', include_top=False)\n",
    "    return model.predict(preprocess_input(tensor))\n",
    "\n",
    "train_tensors = bottleneck_features(train_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6941, 5, 5, 2048) (6941, 101)\n",
      "(1736, 5, 5, 2048) (1736, 101)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_tensors, train_target, test_size = 0.2, random_state=47)\n",
    "\n",
    "print (x_train.shape, y_train.shape)\n",
    "print (x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_9 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 101)               103525    \n",
      "=================================================================\n",
      "Total params: 2,201,701\n",
      "Trainable params: 2,201,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GlobalAveragePooling2D(input_shape=x_train.shape[1:]))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(101, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile the model\n",
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6941 samples, validate on 1736 samples\n",
      "Epoch 1/80\n",
      "6880/6941 [============================>.] - ETA: 0s - loss: 3.7914 - acc: 0.2156Epoch 00000: val_loss improved from inf to 3.44887, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 3s - loss: 3.7916 - acc: 0.2158 - val_loss: 3.4489 - val_acc: 0.2644\n",
      "Epoch 2/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 3.2730 - acc: 0.2970Epoch 00001: val_loss improved from 3.44887 to 3.08639, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 3.2738 - acc: 0.2971 - val_loss: 3.0864 - val_acc: 0.3416\n",
      "Epoch 3/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 2.9956 - acc: 0.3451Epoch 00002: val_loss improved from 3.08639 to 2.82523, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 2.9990 - acc: 0.3446 - val_loss: 2.8252 - val_acc: 0.3859\n",
      "Epoch 4/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 2.7721 - acc: 0.3761Epoch 00003: val_loss improved from 2.82523 to 2.67178, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 2.7719 - acc: 0.3759 - val_loss: 2.6718 - val_acc: 0.4061\n",
      "Epoch 5/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 2.6380 - acc: 0.4052Epoch 00004: val_loss improved from 2.67178 to 2.52514, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 2.6342 - acc: 0.4056 - val_loss: 2.5251 - val_acc: 0.4355\n",
      "Epoch 6/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 2.4998 - acc: 0.4270Epoch 00005: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 2.4999 - acc: 0.4270 - val_loss: 2.5730 - val_acc: 0.4171\n",
      "Epoch 7/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 2.4394 - acc: 0.4323Epoch 00006: val_loss improved from 2.52514 to 2.40623, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 2.4405 - acc: 0.4321 - val_loss: 2.4062 - val_acc: 0.4424\n",
      "Epoch 8/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 2.3356 - acc: 0.4467Epoch 00007: val_loss improved from 2.40623 to 2.36681, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 2.3371 - acc: 0.4465 - val_loss: 2.3668 - val_acc: 0.4562\n",
      "Epoch 9/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 2.2643 - acc: 0.4659Epoch 00008: val_loss improved from 2.36681 to 2.32357, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 2.2646 - acc: 0.4662 - val_loss: 2.3236 - val_acc: 0.4476\n",
      "Epoch 10/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 2.2041 - acc: 0.4768Epoch 00009: val_loss improved from 2.32357 to 2.25663, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 2.2067 - acc: 0.4762 - val_loss: 2.2566 - val_acc: 0.4677\n",
      "Epoch 11/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 2.1470 - acc: 0.4900Epoch 00010: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 2.1483 - acc: 0.4898 - val_loss: 2.8537 - val_acc: 0.3796\n",
      "Epoch 12/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 2.1351 - acc: 0.4872Epoch 00011: val_loss improved from 2.25663 to 2.18088, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 2.1369 - acc: 0.4868 - val_loss: 2.1809 - val_acc: 0.4844\n",
      "Epoch 13/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 2.0807 - acc: 0.4965Epoch 00012: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 2.0820 - acc: 0.4959 - val_loss: 2.3696 - val_acc: 0.4332\n",
      "Epoch 14/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 2.0690 - acc: 0.5026Epoch 00013: val_loss improved from 2.18088 to 2.10495, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 2.0704 - acc: 0.5028 - val_loss: 2.1049 - val_acc: 0.5052\n",
      "Epoch 15/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.9815 - acc: 0.5214Epoch 00014: val_loss improved from 2.10495 to 2.09200, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.9803 - acc: 0.5220 - val_loss: 2.0920 - val_acc: 0.4994\n",
      "Epoch 16/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.9558 - acc: 0.5252Epoch 00015: val_loss improved from 2.09200 to 2.08635, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.9517 - acc: 0.5259 - val_loss: 2.0864 - val_acc: 0.5052\n",
      "Epoch 17/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.9082 - acc: 0.5390Epoch 00016: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.9053 - acc: 0.5394 - val_loss: 2.1378 - val_acc: 0.4925\n",
      "Epoch 18/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.8649 - acc: 0.5406Epoch 00017: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.8652 - acc: 0.5404 - val_loss: 2.1294 - val_acc: 0.5029\n",
      "Epoch 19/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.8574 - acc: 0.5407Epoch 00018: val_loss improved from 2.08635 to 2.04998, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.8563 - acc: 0.5411 - val_loss: 2.0500 - val_acc: 0.5248\n",
      "Epoch 20/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.8074 - acc: 0.5486Epoch 00019: val_loss improved from 2.04998 to 2.01950, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.8069 - acc: 0.5480 - val_loss: 2.0195 - val_acc: 0.5132\n",
      "Epoch 21/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.7936 - acc: 0.5632Epoch 00020: val_loss improved from 2.01950 to 2.01831, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.7907 - acc: 0.5636 - val_loss: 2.0183 - val_acc: 0.5271\n",
      "Epoch 22/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.7742 - acc: 0.5570Epoch 00021: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.7747 - acc: 0.5570 - val_loss: 2.1393 - val_acc: 0.4948\n",
      "Epoch 23/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.7536 - acc: 0.5630Epoch 00022: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.7532 - acc: 0.5630 - val_loss: 2.0556 - val_acc: 0.5023\n",
      "Epoch 24/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.7162 - acc: 0.5807Epoch 00023: val_loss improved from 2.01831 to 1.99707, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.7158 - acc: 0.5805 - val_loss: 1.9971 - val_acc: 0.5374\n",
      "Epoch 25/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.6657 - acc: 0.5803Epoch 00024: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.6656 - acc: 0.5802 - val_loss: 2.0253 - val_acc: 0.5023\n",
      "Epoch 26/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.6876 - acc: 0.5696Epoch 00025: val_loss improved from 1.99707 to 1.97008, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.6871 - acc: 0.5695 - val_loss: 1.9701 - val_acc: 0.5173\n",
      "Epoch 27/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.6396 - acc: 0.5842Epoch 00026: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.6405 - acc: 0.5845 - val_loss: 1.9930 - val_acc: 0.5323\n",
      "Epoch 28/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.6256 - acc: 0.5910Epoch 00027: val_loss improved from 1.97008 to 1.93708, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.6259 - acc: 0.5907 - val_loss: 1.9371 - val_acc: 0.5409\n",
      "Epoch 29/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.5887 - acc: 0.5997Epoch 00028: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.5885 - acc: 0.5995 - val_loss: 2.0019 - val_acc: 0.5380\n",
      "Epoch 30/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.5974 - acc: 0.6004Epoch 00029: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.5971 - acc: 0.6001 - val_loss: 1.9997 - val_acc: 0.5207\n",
      "Epoch 31/80\n",
      "6880/6941 [============================>.] - ETA: 0s - loss: 1.5590 - acc: 0.6003Epoch 00030: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.5560 - acc: 0.6006 - val_loss: 1.9513 - val_acc: 0.5415\n",
      "Epoch 32/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.5543 - acc: 0.6068Epoch 00031: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.5541 - acc: 0.6067 - val_loss: 2.0207 - val_acc: 0.5098\n",
      "Epoch 33/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.5566 - acc: 0.6101Epoch 00032: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.5578 - acc: 0.6096 - val_loss: 1.9962 - val_acc: 0.5276\n",
      "Epoch 34/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.5441 - acc: 0.6114Epoch 00033: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.5430 - acc: 0.6113 - val_loss: 1.9546 - val_acc: 0.5328\n",
      "Epoch 35/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.5173 - acc: 0.6075Epoch 00034: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.5163 - acc: 0.6081 - val_loss: 2.0488 - val_acc: 0.5219\n",
      "Epoch 36/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.5258 - acc: 0.6062Epoch 00035: val_loss improved from 1.93708 to 1.90455, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.5250 - acc: 0.6068 - val_loss: 1.9045 - val_acc: 0.5426\n",
      "Epoch 37/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.4800 - acc: 0.6275Epoch 00036: val_loss improved from 1.90455 to 1.89295, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.4843 - acc: 0.6263 - val_loss: 1.8930 - val_acc: 0.5501\n",
      "Epoch 38/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.4458 - acc: 0.6281Epoch 00037: val_loss improved from 1.89295 to 1.89140, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.4437 - acc: 0.6286 - val_loss: 1.8914 - val_acc: 0.5461\n",
      "Epoch 39/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.4365 - acc: 0.6290Epoch 00038: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.4357 - acc: 0.6290 - val_loss: 1.9479 - val_acc: 0.5397\n",
      "Epoch 40/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.4122 - acc: 0.6346Epoch 00039: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.4113 - acc: 0.6348 - val_loss: 1.9464 - val_acc: 0.5484\n",
      "Epoch 41/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.4091 - acc: 0.6378Epoch 00040: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.4105 - acc: 0.6369 - val_loss: 1.9628 - val_acc: 0.5455\n",
      "Epoch 42/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.4249 - acc: 0.6326Epoch 00041: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.4259 - acc: 0.6322 - val_loss: 2.1442 - val_acc: 0.5069\n",
      "Epoch 43/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.4231 - acc: 0.6332Epoch 00042: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.4216 - acc: 0.6336 - val_loss: 2.0626 - val_acc: 0.5144\n",
      "Epoch 44/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.4298 - acc: 0.6307Epoch 00043: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.4287 - acc: 0.6310 - val_loss: 1.9205 - val_acc: 0.5438\n",
      "Epoch 45/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.3844 - acc: 0.6422Epoch 00044: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.3860 - acc: 0.6423 - val_loss: 1.9581 - val_acc: 0.5403\n",
      "Epoch 46/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.3635 - acc: 0.6442Epoch 00045: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.3646 - acc: 0.6444 - val_loss: 1.8997 - val_acc: 0.5547\n",
      "Epoch 47/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.3398 - acc: 0.6510Epoch 00046: val_loss improved from 1.89140 to 1.83591, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.3401 - acc: 0.6508 - val_loss: 1.8359 - val_acc: 0.5662\n",
      "Epoch 48/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.3185 - acc: 0.6545Epoch 00047: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.3185 - acc: 0.6545 - val_loss: 1.8873 - val_acc: 0.5455\n",
      "Epoch 49/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.3172 - acc: 0.6607Epoch 00048: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.3180 - acc: 0.6606 - val_loss: 1.8908 - val_acc: 0.5536\n",
      "Epoch 50/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.3097 - acc: 0.6604Epoch 00049: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.3075 - acc: 0.6611 - val_loss: 1.8650 - val_acc: 0.5611\n",
      "Epoch 51/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.2698 - acc: 0.6691Epoch 00050: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.2695 - acc: 0.6694 - val_loss: 1.9925 - val_acc: 0.5363\n",
      "Epoch 52/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.3105 - acc: 0.6610Epoch 00051: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.3109 - acc: 0.6610 - val_loss: 1.8546 - val_acc: 0.5622\n",
      "Epoch 53/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.2469 - acc: 0.6717Epoch 00052: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.2460 - acc: 0.6715 - val_loss: 1.9346 - val_acc: 0.5588\n",
      "Epoch 54/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.2541 - acc: 0.6643Epoch 00053: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.2529 - acc: 0.6646 - val_loss: 1.8407 - val_acc: 0.5680\n",
      "Epoch 55/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.2126 - acc: 0.6807Epoch 00054: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.2124 - acc: 0.6806 - val_loss: 1.9210 - val_acc: 0.5484\n",
      "Epoch 56/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.2234 - acc: 0.6733Epoch 00055: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.2223 - acc: 0.6734 - val_loss: 1.9282 - val_acc: 0.5513\n",
      "Epoch 57/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.2956 - acc: 0.6616Epoch 00056: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.2956 - acc: 0.6616 - val_loss: 1.8776 - val_acc: 0.5605\n",
      "Epoch 58/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.2427 - acc: 0.6741Epoch 00057: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.2416 - acc: 0.6747 - val_loss: 1.8410 - val_acc: 0.5547\n",
      "Epoch 59/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.1933 - acc: 0.6857Epoch 00058: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.1930 - acc: 0.6859 - val_loss: 1.8948 - val_acc: 0.5645\n",
      "Epoch 60/80\n",
      "6880/6941 [============================>.] - ETA: 0s - loss: 1.2253 - acc: 0.6750Epoch 00059: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.2265 - acc: 0.6750 - val_loss: 1.9112 - val_acc: 0.5495\n",
      "Epoch 61/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.1953 - acc: 0.6812Epoch 00060: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.1940 - acc: 0.6817 - val_loss: 1.8557 - val_acc: 0.5801\n",
      "Epoch 62/80\n",
      "6880/6941 [============================>.] - ETA: 0s - loss: 1.1891 - acc: 0.6852Epoch 00061: val_loss improved from 1.83591 to 1.82568, saving model to weights.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6941/6941 [==============================] - 2s - loss: 1.1893 - acc: 0.6845 - val_loss: 1.8257 - val_acc: 0.5772\n",
      "Epoch 63/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.1449 - acc: 0.6933Epoch 00062: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.1456 - acc: 0.6934 - val_loss: 1.9172 - val_acc: 0.5582\n",
      "Epoch 64/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.1979 - acc: 0.6778Epoch 00063: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.1969 - acc: 0.6780 - val_loss: 1.9652 - val_acc: 0.5426\n",
      "Epoch 65/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.2158 - acc: 0.6738Epoch 00064: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.2144 - acc: 0.6741 - val_loss: 1.8549 - val_acc: 0.5657\n",
      "Epoch 66/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.1592 - acc: 0.6890Epoch 00065: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.1595 - acc: 0.6888 - val_loss: 1.8877 - val_acc: 0.5582\n",
      "Epoch 67/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.1548 - acc: 0.6877Epoch 00066: val_loss improved from 1.82568 to 1.81215, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.1553 - acc: 0.6877 - val_loss: 1.8121 - val_acc: 0.5691\n",
      "Epoch 68/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.1274 - acc: 0.6964Epoch 00067: val_loss improved from 1.81215 to 1.81055, saving model to weights.best.hdf5\n",
      "6941/6941 [==============================] - 2s - loss: 1.1243 - acc: 0.6973 - val_loss: 1.8106 - val_acc: 0.5801\n",
      "Epoch 69/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.0953 - acc: 0.7078Epoch 00068: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.0971 - acc: 0.7071 - val_loss: 1.8516 - val_acc: 0.5801\n",
      "Epoch 70/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.1003 - acc: 0.7038Epoch 00069: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.0981 - acc: 0.7045 - val_loss: 1.8241 - val_acc: 0.5709\n",
      "Epoch 71/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.0656 - acc: 0.7103Epoch 00070: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.0688 - acc: 0.7093 - val_loss: 1.8383 - val_acc: 0.5720\n",
      "Epoch 72/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.0646 - acc: 0.7110Epoch 00071: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.0648 - acc: 0.7110 - val_loss: 1.8193 - val_acc: 0.5783\n",
      "Epoch 73/80\n",
      "6880/6941 [============================>.] - ETA: 0s - loss: 1.0729 - acc: 0.7096Epoch 00072: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.0708 - acc: 0.7098 - val_loss: 1.8517 - val_acc: 0.5662\n",
      "Epoch 74/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.0642 - acc: 0.7109Epoch 00073: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.0645 - acc: 0.7111 - val_loss: 1.8789 - val_acc: 0.5582\n",
      "Epoch 75/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.0302 - acc: 0.7184Epoch 00074: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.0298 - acc: 0.7185 - val_loss: 1.8315 - val_acc: 0.5743\n",
      "Epoch 76/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.0422 - acc: 0.7184Epoch 00075: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.0405 - acc: 0.7186 - val_loss: 1.8313 - val_acc: 0.5801\n",
      "Epoch 77/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.0125 - acc: 0.7293Epoch 00076: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.0149 - acc: 0.7289 - val_loss: 1.9661 - val_acc: 0.5588\n",
      "Epoch 78/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.0805 - acc: 0.7103Epoch 00077: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.0804 - acc: 0.7103 - val_loss: 1.8983 - val_acc: 0.5611\n",
      "Epoch 79/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.0207 - acc: 0.7203Epoch 00078: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.0205 - acc: 0.7204 - val_loss: 2.0361 - val_acc: 0.5323\n",
      "Epoch 80/80\n",
      "6900/6941 [============================>.] - ETA: 0s - loss: 1.0495 - acc: 0.7148Epoch 00079: val_loss did not improve\n",
      "6941/6941 [==============================] - 2s - loss: 1.0484 - acc: 0.7155 - val_loss: 1.9780 - val_acc: 0.5444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5fd2434860>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "### Train the model\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=80, batch_size=20, validation_data=(x_test, y_test),callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 58.0069%\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.argmax(model.predict(np.expand_dims(feature, axis=0))) for feature in x_test]\n",
    "test_accuracy = 100*np.sum(np.array(predictions)==np.argmax(y_test, axis=1))/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
